# ğŸ¬ SuBhashit: AI-Powered Cross-Lingual Video Translator

SuBhashit is an advanced multilingual video translation pipeline that transforms spoken content from one language to another, preserving the **emotion**, **context**, **prosody**, and **speaker style** of the original video. Designed for scale, modularity, and cultural relevance, SuBhashit provides a seamless backend interface for end-to-end video localization.

> **Built with Python 3.12 | FastAPI | PyAnnote | RVC | IndicTTS | Facebook NLLB | Whisper | Transformers**

---

## âœ¨ Features

- ğŸ¯ Automatic video scene segmentation and shot detection
- ğŸ§  Speaker diarization, gender/age/accent/emotion recognition
- âœï¸ High-quality ASR and emotion-aware neural translation
- ğŸ—£ï¸ Prosody-aligned text-to-speech with voice cloning
- ğŸ•µï¸â€â™€ï¸ Lip-sync compatible voice synthesis (optional)
- ğŸ’¬ Auto subtitle generation and export/burn-in options
- ğŸ§© Fully modular, extendable, and testable backend

---

## ğŸ› ï¸ Pipeline Architecture

### ğŸ”¹ 1. Preprocessing
- **Video Ingestion** â€“ Load video, validate resolution/framerate
- **Scene & Shot Detection** â€“ Segment into logical scenes and fine-grained shots

### ğŸ”¹ 2. Audio Processing
- **Audio Extraction & Normalization** â€“ Isolate and standardize audio
- **Noise Reduction** â€“ Enhance clarity and reduce background noise
- **Speaker Diarization** â€“ PyAnnote-based multi-speaker separation
- **Demographic & Emotion Analysis** â€“ Detect gender, age, accent, emotion

### ğŸ”¹ 3. Speech-to-Text & NLP
- **ASR** â€“ Transcribe speech (Whisper)
- **Punctuation & Cleanup** â€“ Format output and remove disfluencies
- **NER & Idiom Detection** â€“ Detect entities and culturally-bound phrases
- **Text Emotion Analysis** â€“ Emotional tone from transcribed content

### ğŸ”¹ 4. Translation & Localization
- **Translation** â€“ Neural machine translation via Facebook NLLB-200 distilled
- **Cultural Adaptation** â€“ Idiom/context/localization adaptation
- **Keyword Tagging** â€“ Highlight key terms, maintain translation fidelity

### ğŸ”¹ 5. Voice Synthesis
- **Prosody Mapping** â€“ Align prosody to translated text
- **TTS** â€“ AI4Bharat IndicParlerTTS + RVC voice cloning
- **Duration Control** â€“ Adjust speech length, stretch/compress timing

### ğŸ”¹ 6. Video Reconstruction
- **Audio Sync & Lip Alignment** â€“ Sync audio with visual cues
- **Subtitles** â€“ Auto-generate styled SRT or hardcoded subtitles

### ğŸ”¹ 7. Postprocessing
- **Encoding** â€“ Compress final output for deployment
- **QA & Export** â€“ Final validation and delivery

---

## ğŸ“ Project Structure

```
project_root/
â”œâ”€â”€ app/                      # FastAPI Application Layer
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â”œâ”€â”€ pipeline.py
â”‚   â”‚   â”œâ”€â”€ preprocess.py
â”‚   â”‚   â”œâ”€â”€ generation.py
â”‚   â”‚   â”œâ”€â”€ text_analysis.py
â”‚   â”‚   â””â”€â”€ voice_analysis.py
â”‚   â””â”€â”€ dependencies.py
â”‚
â”œâ”€â”€ core/                     # Pipeline Orchestration
â”‚   â”œâ”€â”€ config.py
â”‚   â””â”€â”€ pipeline_controller.py
â”‚
â”œâ”€â”€ modules/
â”‚   â”œâ”€â”€ preprocessing/
â”‚   â”œâ”€â”€ voice_analysis/
â”‚   â”œâ”€â”€ text_analysis/
â”‚   â””â”€â”€ generation/
â”‚
â”œâ”€â”€ models/                   # Pretrained Model Weights
â”‚   â”œâ”€â”€ voice/
â”‚   â””â”€â”€ text/
â”‚
â”œâ”€â”€ utils/                    # Logging, File & Audio Tools
â”œâ”€â”€ data/                     # Input/Processed/Output Media
â”œâ”€â”€ tests/                    # Unit & Integration Tests
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸ“¦ Dependencies

**Core Libraries & Frameworks:**
- `FastAPI`, `uvicorn`, `pydantic`, `ffmpeg-python`
- `PyAnnote` â€“ speaker diarization
- `whisper`, `transformers`, `sentencepiece`
- `facebook/nllb-200-distilled-600M` â€“ translation
- `ai4bharat/IndicParlerTTS` â€“ TTS for Indian languages
- `RVC` â€“ retrieval-based voice cloning
- `librosa`, `torchaudio`, `scipy`, `numpy`, `spaCy`

---

## ğŸš€ Getting Started

### ğŸ”§ Setup

```bash
git clone https://github.com/your-org/subhashit.git
cd subhashit

python3.12 -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

pip install -r requirements.txt
```

### â–¶ï¸ Run the Server

```bash
uvicorn app.main:app --reload
```

### ğŸ“¬ API Example

#### POST `/pipeline/run`
```json
{
  "input_video_path": "data/input/sample.mp4",
  "target_language": "hi"
}
```

Returns: Translated video path, subtitle file

---

## ğŸ§ª Testing

```bash
pytest tests/
```

---

## ğŸ“¤ Output

- ğŸï¸ Translated Video (mp4)
- ğŸ’¬ Subtitles (SRT or burned-in)
- ğŸ—‚ï¸ Logs and intermediate files in `/data/processed`

---

## ğŸ¤ Contributing

We welcome issues, improvements, and new module integrations.
Please submit a pull request or open a discussion.

---

## ğŸ“ License

MIT License Â© 2024 [Your Name or Organization]

---

## ğŸ“š Acknowledgements

- [AI4Bharat](https://ai4bharat.org)
- [Facebook NLLB](https://ai.facebook.com/research/no-language-left-behind)
- [OpenAI Whisper](https://github.com/openai/whisper)
- [RVC Voice Conversion](https://github.com/RVC-Project)
- [PyAnnote Speaker Diarization](https://github.com/pyannote/pyannote-audio)